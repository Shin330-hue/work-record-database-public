#!/usr/bin/env node
/**
 * scripts/migrate-machine-type.js
 *
 * ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã® instruction.json ã‚„ search-index.json ã«å«ã¾ã‚Œã‚‹
 * machineType ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‹±èªã‚­ãƒ¼é…åˆ—ã¸æ­£è¦åŒ–ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚
 *
 * ä½¿ç”¨ä¾‹:
 *   node scripts/migrate-machine-type.js --dry-run
 *   node scripts/migrate-machine-type.js
 *   node scripts/migrate-machine-type.js --no-backup
 */

const fs = require('fs/promises')
const path = require('path')

const args = process.argv.slice(2)
const dryRun = args.includes('--dry-run')
const noBackup = args.includes('--no-backup')
const targetRootArgIndex = args.findIndex(arg => arg === '--target')
const targetRoot =
  targetRootArgIndex !== -1 && args[targetRootArgIndex + 1]
    ? path.resolve(args[targetRootArgIndex + 1])
    : path.resolve(process.cwd(), 'public', 'data')

const WORK_INSTRUCTIONS_DIR = path.join(targetRoot, 'work-instructions')
const SEARCH_INDEX_PATH = path.join(targetRoot, 'search-index.json')

const MACHINE_TYPE_KEYS = ['machining', 'turning', 'yokonaka', 'radial', 'other']

const MACHINE_TYPE_MAP = {
  'ãƒã‚·ãƒ‹ãƒ³ã‚°': 'machining',
  'ãƒã‚·ãƒ‹ãƒ³ã‚°ã‚»ãƒ³ã‚¿': 'machining',
  'ãƒã‚·ãƒ‹ãƒ³ã‚°ã‚»ãƒ³ã‚¿ãƒ¼': 'machining',
  'machining': 'machining',
  'mc': 'machining',

  'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°': 'turning',
  'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒ³ã‚¿': 'turning',
  'cncæ—‹ç›¤': 'turning',
  'æ—‹ç›¤': 'turning',
  'turning': 'turning',
  'lathe': 'turning',

  'æ¨ªä¸­': 'yokonaka',
  'æ¨ªä¸­ãã‚Š': 'yokonaka',
  'æ¨ªä¸­ãã‚Šç›¤': 'yokonaka',
  'horizontal': 'yokonaka',
  'yokonaka': 'yokonaka',

  'ãƒ©ã‚¸ã‚¢ãƒ«': 'radial',
  'ãƒ©ã‚¸ã‚¢ãƒ«ãƒœãƒ¼ãƒ«ç›¤': 'radial',
  'ãƒœãƒ¼ãƒ«ç›¤': 'radial',
  'drill': 'radial',
  'radial': 'radial',

  'ãƒ•ãƒ©ã‚¤ã‚¹': 'other',
  'ãƒ•ãƒ©ã‚¤ã‚¹ç›¤': 'other',
  'ãã®ä»–': 'other',
  'other': 'other'
}

async function ensureBackup(filePath) {
  if (dryRun || noBackup) return
  try {
    await fs.copyFile(filePath, `${filePath}.bak`)
  } catch (error) {
    if (error.code !== 'EEXIST') {
      console.warn(`âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ (${filePath}):`, error.message)
    }
  }
}

function normalizeMachineType(value) {
  if (value == null) return []

  const rawValues = Array.isArray(value)
    ? value
    : String(value)
        .split(',')
        .map((item) => item.trim())
        .filter(Boolean)

  const result = []
  for (const raw of rawValues) {
    if (!raw) continue
    const lower = raw.toLowerCase()
    const mapped =
      MACHINE_TYPE_MAP[raw] ??
      MACHINE_TYPE_MAP[lower] ??
      MACHINE_TYPE_MAP[raw.replace(/\s+/g, '')] ??
      MACHINE_TYPE_MAP[lower.replace(/\s+/g, '')]

    const key = MACHINE_TYPE_KEYS.includes(mapped) ? mapped : 'other'
    if (!result.includes(key)) {
      result.push(key)
    }
  }

  return result
}

async function migrateInstructionFiles() {
  let updatedCount = 0
  let skippedCount = 0

  try {
    const entries = await fs.readdir(WORK_INSTRUCTIONS_DIR, { withFileTypes: true })
    for (const entry of entries) {
      if (!entry.isDirectory() || !entry.name.startsWith('drawing-')) continue

      const instructionPath = path.join(WORK_INSTRUCTIONS_DIR, entry.name, 'instruction.json')
      try {
        const fileContent = await fs.readFile(instructionPath, 'utf-8')
        const json = JSON.parse(fileContent)

        const normalized = normalizeMachineType(json?.metadata?.machineType)
        const current = Array.isArray(json?.metadata?.machineType)
          ? json.metadata.machineType
          : []

        const isDifferent =
          normalized.length !== current.length ||
          normalized.some((val, idx) => current[idx] !== val)

        if (isDifferent) {
          json.metadata = {
            ...json.metadata,
            machineType: normalized
          }

          await ensureBackup(instructionPath)
          if (!dryRun) {
            await fs.writeFile(instructionPath, JSON.stringify(json, null, 2) + '\n')
          }
          updatedCount++
          console.log(`${dryRun ? 'ğŸ“ (dry-run)' : 'âœ…'} ${instructionPath}: machineType -> [${normalized.join(', ')}]`)
        } else {
          skippedCount++
        }
      } catch (error) {
        console.warn(`âš ï¸ instruction.json ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ (${instructionPath}):`, error.message)
      }
    }
  } catch (error) {
    console.warn('âš ï¸ work-instructions ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ:', error.message)
  }

  return { updatedCount, skippedCount }
}

async function migrateSearchIndex() {
  try {
    const fileContent = await fs.readFile(SEARCH_INDEX_PATH, 'utf-8')
    const searchIndex = JSON.parse(fileContent)
    let changed = false

    const normalizedDrawings = (searchIndex.drawings || []).map((drawing) => {
      const normalized = normalizeMachineType(drawing.machineType)
      const current = Array.isArray(drawing.machineType) ? drawing.machineType : []
      const isDifferent =
        normalized.length !== current.length ||
        normalized.some((val, idx) => current[idx] !== val)

      if (isDifferent) {
        changed = true
        return {
          ...drawing,
          machineType: normalized
        }
      }
      return drawing
    })

    if (changed) {
      await ensureBackup(SEARCH_INDEX_PATH)
      if (!dryRun) {
        const updated = {
          ...searchIndex,
          drawings: normalizedDrawings
        }
        await fs.writeFile(SEARCH_INDEX_PATH, JSON.stringify(updated, null, 2) + '\n')
      }
      console.log(`${dryRun ? 'ğŸ“ (dry-run)' : 'âœ…'} search-index.json: machineType æ­£è¦åŒ–å®Œäº†`)
    } else {
      console.log('â„¹ï¸ search-index.json: å¤‰æ›´ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
    }
  } catch (error) {
    console.warn(`âš ï¸ search-index.json ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ (${SEARCH_INDEX_PATH}):`, error.message)
  }
}

;(async function main() {
  console.log('--- machineType æ­£è¦åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ---')
  console.log(`å¯¾è±¡ãƒ«ãƒ¼ãƒˆ: ${targetRoot}`)
  console.log(`ãƒ¢ãƒ¼ãƒ‰: ${dryRun ? 'dry-run (æ›¸ãè¾¼ã¿ãªã—)' : 'å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰'}`)
  console.log(`ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ${noBackup ? 'ä½œæˆã—ãªã„ (--no-backup)' : 'ä½œæˆã™ã‚‹'}`)

  const { updatedCount, skippedCount } = await migrateInstructionFiles()
  await migrateSearchIndex()

  console.log('----------------------------------')
  console.log(`instruction.json æ›´æ–°: ${updatedCount} ä»¶ (${skippedCount} ä»¶ã¯å¤‰æ›´ãªã—)`)
  console.log('å‡¦ç†å®Œäº†')
})()
